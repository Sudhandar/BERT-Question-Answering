{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT- Question and Answering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17d733f18d66460a868e6a2de23ecf51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4659e134e456478995c897b46ca50552",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f16da1317f874f35bdb223becefa27f6",
              "IPY_MODEL_7341f64b7e4f4899a6eebb86bef6e0a1"
            ]
          }
        },
        "4659e134e456478995c897b46ca50552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f16da1317f874f35bdb223becefa27f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ebcf1e9d6c184ca79128db3b172ef1e6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6fb2b41bf7345ac8f0ab7255f9362d2"
          }
        },
        "7341f64b7e4f4899a6eebb86bef6e0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c36acd27aa747138d1748060867ceff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 2.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b64a4493e4d41cf9df6e81ca8ca1d00"
          }
        },
        "ebcf1e9d6c184ca79128db3b172ef1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6fb2b41bf7345ac8f0ab7255f9362d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c36acd27aa747138d1748060867ceff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b64a4493e4d41cf9df6e81ca8ca1d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudhandar/BERT-Question-Answering/blob/master/BERT_Question_and_Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqR9cK3zblzA"
      },
      "source": [
        "# Question and Answering on the SQuAD Dataset- BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L44qd03cIwB"
      },
      "source": [
        "Fine tuning BERT for Question Answering and testing on the SQuAD v1.1 benchmark. The model is trained on the GPU provided by Google Colab.Fine tuning BERT results in an increase in the F1 Score compared to the pretuned BERT model.The process can be grouped into five sections,\n",
        "\n",
        "1.   Loading the dataset\n",
        "2.   Data Preprocessing\n",
        "3.   Fine-Tuning BERT\n",
        "4.   Performance on the test set\n",
        "5.   Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VjmKu_saHNG"
      },
      "source": [
        "# 1.Loading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "\n",
        "This notebook is already configured to use a GPU, incase if you run into an issue, please do the following,\n",
        "\n",
        "`Edit ðŸ¡’ Notebook Settings ðŸ¡’ Hardware accelerator ðŸ¡’ (GPU)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "Instructing PyTorch to use the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533bd965-70f0-4122-95a2-7f99fb428d98"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('Current GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Current GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2eujBEUxf8k"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "**Installing transformers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn"
      },
      "source": [
        "\n",
        "I have used the [transformers](https://github.com/huggingface/transformers) package from huggingface which gives a pytorch interface for working with BERT.The library  includes pre-built modifications suited to question and answering task, known as `BertForQuestionAnswering`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npF6oYe3I551"
      },
      "source": [
        "**Downloading Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZNVW6xd0T0X"
      },
      "source": [
        "`wget` package is used to download the dataset to the Colab instance's file system. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08pO03Ff1BjI"
      },
      "source": [
        "The dataset is hosted on GitHub in this repo: https://rajpurkar.github.io/SQuAD-explorer/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3e915a-e1a7-44ff-a948-0d4a95bbb741"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "local_dir = './squad_dataset/'\n",
        "\n",
        "# The filenames and URLs for the dataset files.\n",
        "files = [('train-v1.1.json', 'https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json'), \n",
        "         ('dev-v1.1.json', 'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json'),\n",
        "         ('evaluate-v1.1.py', 'https://github.com/allenai/bi-att-flow/blob/master/squad/evaluate-v1.1.py')]\n",
        "\n",
        "if not os.path.exists(local_dir):\n",
        "    os.mkdir(local_dir)\n",
        "\n",
        "for (filename, url) in files:\n",
        "    file_path = local_dir + filename\n",
        "    if not os.path.exists(file_path):\n",
        "        print('  ' + file_path)\n",
        "        wget.download(url, local_dir + filename)\n",
        "print('Done!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "  ./squad_dataset/train-v1.1.json\n",
            "  ./squad_dataset/dev-v1.1.json\n",
            "  ./squad_dataset/evaluate-v1.1.py\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cZA5x_UA7dN"
      },
      "source": [
        "Printing file size and location in the drive.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D87pElNqYqVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6422bc-a24b-4c6a-98c7-44fa45ef69b1"
      },
      "source": [
        "data_dir = './squad_dataset/'\n",
        "files = list(os.listdir(data_dir))\n",
        "\n",
        "print('Dataset Location:')\n",
        "print(data_dir)\n",
        "for f in files:\n",
        "    f_size = float(os.stat(data_dir + '/' + f).st_size) / 2**20\n",
        "    print(\"     {:25s}    {:>6.2f} MB\".format(f, f_size))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Location:\n",
            "./squad_dataset/\n",
            "     dev-v1.1.json                  4.63 MB\n",
            "     evaluate-v1.1.py               0.13 MB\n",
            "     train-v1.1.json               28.89 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFrrVK-HDOEj"
      },
      "source": [
        "**Parsing the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VyKjSdzMGw6"
      },
      "source": [
        "The SQuAD dataset is stored in 'json' format. There 87,599 training samples in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm1wTn09RAR7"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(os.path.join('./squad_dataset/train-v1.1.json'), \"r\", encoding=\"utf-8\") as reader:\n",
        "    input_data = json.load(reader)[\"data\"]\n",
        "\n",
        "examples = []\n",
        "for entry in input_data:\n",
        "    title = entry[\"title\"]\n",
        "    print('  ', title)\n",
        "    for paragraph in entry[\"paragraphs\"]:\n",
        "        context_text = paragraph[\"context\"]\n",
        "        for qa in paragraph[\"qas\"]:\n",
        "            ex = {}\n",
        "            ex['qas_id'] = qa[\"id\"]\n",
        "            ex['question_text'] = qa[\"question\"]\n",
        "            answer = qa[\"answers\"][0]\n",
        "            ex['answer_text'] = answer[\"text\"]\n",
        "            ex['start_position_character'] = answer[\"answer_start\"]                \n",
        "            ex['title'] = title\n",
        "            ex['context_text'] = context_text\n",
        "            examples.append(ex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnhuQxpvZzmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d00e51-fa23-44ad-d009-aa115e7a8d5c"
      },
      "source": [
        "print('There are {:,} training examples.'.format(len(examples)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 87,599 training examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPlLOPwzDR87"
      },
      "source": [
        "**Inspecting Examples:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8OZ4ZWSClyd"
      },
      "source": [
        "Each example has a **question**, and a **context**, which is the reference text in which the answer can be found. \n",
        "\n",
        "\n",
        "Here are some of the field descriptions from the code:\n",
        "* **qas_id**: The example's unique identifier\n",
        "* **title**: Article title\n",
        "* **question_text**: The question string\n",
        "* **context_text**: The context string\n",
        "* **answer_text**: The answer string\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIC3pmmgIHjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270d22d3-773d-4333-b26f-6e57dc1179d8"
      },
      "source": [
        "import textwrap\n",
        "\n",
        "wrapper = textwrap.TextWrapper(width=80) \n",
        "ex = examples[260]\n",
        "print('Title:', ex['title'])\n",
        "print('ID:', ex['qas_id'])\n",
        "\n",
        "print('\\n======== Question =========')\n",
        "print(ex['question_text'])\n",
        "\n",
        "print('\\n======== Context =========')\n",
        "print(wrapper.fill(ex['context_text']))\n",
        "\n",
        "print('\\n======== Answer =========')\n",
        "print(ex['answer_text'])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title: University_of_Notre_Dame\n",
            "ID: 5733ccbe4776f41900661271\n",
            "\n",
            "======== Question =========\n",
            "In what film did a parody of the \"Win one for the Gipper\" speech appear?\n",
            "\n",
            "======== Context =========\n",
            "In the film Knute Rockne, All American, Knute Rockne (played by Pat O'Brien)\n",
            "delivers the famous \"Win one for the Gipper\" speech, at which point the\n",
            "background music swells with the \"Notre Dame Victory March\". George Gipp was\n",
            "played by Ronald Reagan, whose nickname \"The Gipper\" was derived from this role.\n",
            "This scene was parodied in the movie Airplane! with the same background music,\n",
            "only this time honoring George Zipp, one of Ted Striker's former comrades. The\n",
            "song also was prominent in the movie Rudy, with Sean Astin as Daniel \"Rudy\"\n",
            "Ruettiger, who harbored dreams of playing football at the University of Notre\n",
            "Dame despite significant obstacles.\n",
            "\n",
            "======== Answer =========\n",
            "Airplane!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csoyhyZzSSg_"
      },
      "source": [
        "**Helper Functions:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFbCV6IRSUJ1"
      },
      "source": [
        "Few helper functions used in the Notebook. They are:\n",
        "\n",
        "* **format_time** - Converts floating point seconds into hh:mm:ss\n",
        "* **good_update_interval** - For printing updates, this will choose an interval.\n",
        "* **check_gpu_mem** - Reports how much of the GPU's memory we're using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTnXQP7CcDSe"
      },
      "source": [
        "Helper function for formatting elapsed times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ginim8z1VX2K"
      },
      "source": [
        "Helper function to automatically pick a reasonable interval for printing out a progress update during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do7r4TRjexrc"
      },
      "source": [
        "def good_update_interval(total_iters, num_desired_updates):\n",
        "    '''\n",
        "    Progress update interval based on the magnitude of the total iterations.\n",
        "    Parameters:\n",
        "      `total_iters` - The number of iterations in the for-loop.\n",
        "      `num_desired_updates` - How many times we want to see an update over the \n",
        "                              course of the for-loop.\n",
        "    '''\n",
        "    exact_interval = total_iters / num_desired_updates\n",
        "    order_of_mag = len(str(total_iters)) - 1\n",
        "    round_mag = order_of_mag - 1\n",
        "    update_interval = int(round(exact_interval, -round_mag))\n",
        "    if update_interval == 0:\n",
        "        update_interval = 1\n",
        "    return update_interval"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKetqAKJiwpj"
      },
      "source": [
        "Helper function to report current GPU memory usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRJBBgfZiwpl"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "def check_gpu_mem():\n",
        "    '''\n",
        "    Uses Nvidia's SMI tool to check the current GPU memory usage.\n",
        "    '''\n",
        "    buf = os.popen('nvidia-smi --query-gpu=memory.total,memory.used --format=csv')\n",
        "    reader = csv.reader(buf, delimiter=',')\n",
        "    df = pd.DataFrame(reader)\n",
        "    new_header = df.iloc[0]\n",
        "    df = df[1:]\n",
        "    df.columns = new_header\n",
        "    return df"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk4InpYWDWWi"
      },
      "source": [
        "# 2.Data Preprocessing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzHxH9Uw2VQH"
      },
      "source": [
        " Analyzing the distribution of sequence lengths to finalize the truncation strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znwmOxQsl9fE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "17d733f18d66460a868e6a2de23ecf51",
            "4659e134e456478995c897b46ca50552",
            "f16da1317f874f35bdb223becefa27f6",
            "7341f64b7e4f4899a6eebb86bef6e0a1",
            "ebcf1e9d6c184ca79128db3b172ef1e6",
            "e6fb2b41bf7345ac8f0ab7255f9362d2",
            "0c36acd27aa747138d1748060867ceff",
            "4b64a4493e4d41cf9df6e81ca8ca1d00"
          ]
        },
        "outputId": "e8db7bca-01ff-44e0-8c98-8b1b919b19bd"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    do_lower_case=False\n",
        ")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17d733f18d66460a868e6a2de23ecf51",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeuEDQ8XyrzA"
      },
      "source": [
        "The samples have been tokenized and encoded using the following method: \n",
        "\n",
        "```python\n",
        "tokenizer.encode(ex['question_text'], \n",
        "                 ex['context_text'],\n",
        "                 add_special_tokens = True)\n",
        "```\n",
        "\n",
        "Here are minimum, maximum, and median sequence lengths.\n",
        "\n",
        "```\n",
        "   Min length: 36 tokens\n",
        "   Max length: 882 tokens\n",
        "Median length: 163 tokens\n",
        "```\n",
        "\n",
        "And here is a distribution plot of the sequence lengths. \n",
        "![sequence_length_distribution.png](data:image/png;base64,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)\n",
        "\n",
        "```\n",
        "How many comments will be truncated depending on the max_len?\n",
        "\n",
        "max_len = 128  -->   69,082 of  87,599  (78.9%)  will be truncated \n",
        "max_len = 256  -->    9,812 of  87,599  (11.2%)  will be truncated \n",
        "max_len = 300  -->    4,568 of  87,599  ( 5.2%)  will be truncated \n",
        "max_len = 384  -->    1,087 of  87,599  ( 1.2%)  will be truncated \n",
        "max_len = 512  -->      135 of  87,599  ( 0.2%)  will be truncated \n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgzvZNtgHq4J"
      },
      "source": [
        "**Distributing Sequence Length:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5ISTekrIayp"
      },
      "source": [
        "**Choosing max_len**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff-eSxYL6hZC"
      },
      "source": [
        "Factors that impact the maximum sequence length `max_len`:\n",
        "1. **Training Time** - Training time is quadratic with `max_len`. `max_len = 512` will take 4x  longer to train than `max_len = 256`, and 16x longer than `max_len = 128`!\n",
        "2. **Accuracy** - Truncating the samples to a shorter length will the hurt accuracy, due to the loss of information.\n",
        "3. **GPU Memory** - For 12GB of RAM provided by Google Colab, the maximum length which can be used (without running of memory) is about `max_len = 400`.\n",
        "\n",
        "The maximum sequence length has chosen to be `384` to match the huggingface implementation. Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhrb-u7G-yzW"
      },
      "source": [
        "max_len = 384"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0GHfndc7FlH"
      },
      "source": [
        "**Tokenizing the training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ucdyc5z7TmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbec641-74bc-4e38-a56e-4cf7bdec827f"
      },
      "source": [
        "import torch\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "all_input_ids = []\n",
        "attention_masks = []\n",
        "segment_ids = [] \n",
        "start_positions = []\n",
        "end_positions = []\n",
        "\n",
        "num_dropped = 0\n",
        "\n",
        "update_interval = good_update_interval(\n",
        "            total_iters = len(examples), \n",
        "            num_desired_updates = 15\n",
        "        )\n",
        "\n",
        "print('Tokenizing {:,} examples...'.format(len(examples)))\n",
        "\n",
        "for (ex_num, ex) in enumerate(examples):\n",
        "    if (ex_num % update_interval) == 0 and not (ex_num == 0):\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        ex_per_sec = (time.time() - t0) / ex_num\n",
        "        remaining_sec = ex_per_sec * (len(examples) - ex_num)\n",
        "        remaining = format_time(remaining_sec)\n",
        "        print('  Example {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(ex_num, len(examples), elapsed, remaining))\n",
        "    answer_tokens = tokenizer.tokenize(ex['answer_text'])\n",
        "    sentinel_str = ' '.join(['[MASK]']*len(answer_tokens))\n",
        "    start_char_i = ex['start_position_character']\n",
        "    end_char_i = start_char_i + len(ex['answer_text'])\n",
        "    context_w_sentinel = ex['context_text'][:start_char_i] + \\\n",
        "                         sentinel_str + \\\n",
        "                         ex['context_text'][end_char_i:]\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        ex['question_text'], \n",
        "        context_w_sentinel,\n",
        "        add_special_tokens = True,\n",
        "        max_length = max_len,\n",
        "        pad_to_max_length = True,\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt',\n",
        "    )\n",
        "    input_ids = encoded_dict['input_ids']\n",
        "    is_mask_token = (input_ids[0] == tokenizer.mask_token_id)\n",
        "    mask_token_indices = is_mask_token.nonzero(as_tuple=False)[:, 0]\n",
        "    if not len(mask_token_indices) == len(answer_tokens):\n",
        "        num_dropped += 1\n",
        "        continue\n",
        "    start_index = mask_token_indices[0]\n",
        "    end_index = mask_token_indices[-1]\n",
        "    answer_token_ids = tokenizer.encode(answer_tokens, \n",
        "                                        add_special_tokens=False, \n",
        "                                        return_tensors='pt')\n",
        "    input_ids[0, start_index : end_index + 1] = answer_token_ids\n",
        "    all_input_ids.append(input_ids)\n",
        "    attention_masks.append(encoded_dict['attention_mask'])    \n",
        "    segment_ids.append(encoded_dict['token_type_ids'])\n",
        "    start_positions.append(start_index)\n",
        "    end_positions.append(end_index)\n",
        "\n",
        "all_input_ids = torch.cat(all_input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "segment_ids = torch.cat(segment_ids, dim=0)\n",
        "start_positions = torch.tensor(start_positions)\n",
        "end_positions = torch.tensor(end_positions)\n",
        "print('DONE.  Tokenization took {:}'.format(format_time(time.time() - t0)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing 87,599 examples...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Example   6,000  of   87,599.    Elapsed: 0:00:16. Remaining: 0:03:32\n",
            "  Example  12,000  of   87,599.    Elapsed: 0:00:29. Remaining: 0:03:04\n",
            "  Example  18,000  of   87,599.    Elapsed: 0:00:42. Remaining: 0:02:41\n",
            "  Example  24,000  of   87,599.    Elapsed: 0:00:55. Remaining: 0:02:26\n",
            "  Example  30,000  of   87,599.    Elapsed: 0:01:11. Remaining: 0:02:16\n",
            "  Example  36,000  of   87,599.    Elapsed: 0:01:28. Remaining: 0:02:06\n",
            "  Example  42,000  of   87,599.    Elapsed: 0:01:45. Remaining: 0:01:54\n",
            "  Example  48,000  of   87,599.    Elapsed: 0:02:02. Remaining: 0:01:40\n",
            "  Example  54,000  of   87,599.    Elapsed: 0:02:18. Remaining: 0:01:26\n",
            "  Example  60,000  of   87,599.    Elapsed: 0:02:34. Remaining: 0:01:11\n",
            "  Example  66,000  of   87,599.    Elapsed: 0:02:50. Remaining: 0:00:56\n",
            "  Example  72,000  of   87,599.    Elapsed: 0:03:07. Remaining: 0:00:40\n",
            "  Example  78,000  of   87,599.    Elapsed: 0:03:23. Remaining: 0:00:25\n",
            "  Example  84,000  of   87,599.    Elapsed: 0:03:40. Remaining: 0:00:09\n",
            "DONE.  Tokenization took 0:03:51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl12-BD637Ty"
      },
      "source": [
        "# 3.Fine-Tuning BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw6mvOX8ELxB"
      },
      "source": [
        "**Loading Initial Weights**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txg7XXDsY-es"
      },
      "source": [
        "The `BertForQuestionAnswering` class from the `transformers` library can be used for this project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "from transformers import BertForQuestionAnswering, AdamW, BertConfig\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "desc = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbmX98ovPy2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "e8f43cf8-19f9-4173-cbc7-1efbd372c49c"
      },
      "source": [
        "check_gpu_mem()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>memory.total [MiB]</th>\n",
              "      <th>memory.used [MiB]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15079 MiB</td>\n",
              "      <td>1509 MiB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0 memory.total [MiB]  memory.used [MiB]\n",
              "1          15079 MiB           1509 MiB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "**Sampling and Validation Set**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f83338-ea83-48b3-f8e4-14600a1791ff"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "import numpy as np\n",
        "subsample = True\n",
        "\n",
        "if subsample:\n",
        "    all_indices = np.random.permutation(all_input_ids.shape[0])\n",
        "    indices = all_indices[0:87000]\n",
        "    dataset = TensorDataset(all_input_ids[indices, :], \n",
        "                            attention_masks[indices, :], \n",
        "                            segment_ids[indices, :], \n",
        "                            start_positions[indices], \n",
        "                            end_positions[indices])\n",
        "else:\n",
        "    dataset = TensorDataset(all_input_ids, \n",
        "                            attention_masks, \n",
        "                            segment_ids, \n",
        "                            start_positions, \n",
        "                            end_positions)\n",
        "print('Dataset size: {:} samples'.format(len(dataset)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size: 87000 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "This dataset already has a train / test split, but I'm dividing this training set to use 98% for training and 2% for validation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a6HUzC8wJTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e43770e-9fcd-4a8b-ecca-af12c8531f0c"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.98 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85,260 training samples\n",
            "1,740 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejHQThm_uVnB"
      },
      "source": [
        "**Batch Size and DataLoaders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHk0ZgDSoW6u"
      },
      "source": [
        "BERT authors recommend batch sizes of 16 or 32. Due to our GPU restrictions, I have selected the batch size of 16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d69dc0f-4ff7-4f8f-8cef-c4115f333f59"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler, SequentialSampler\n",
        "import numpy.random\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 12 \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "print('{:,} training batches & {:,} validation batches'.format(len(train_dataloader), len(validation_dataloader)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,105 training batches & 145 validation batches\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "**Optimizer:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values:\n",
        "- Batch size: 16, 32 \n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 3e-5,\n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iaG0A5quuqz"
      },
      "source": [
        "**Epochs and Learning Rate Scheduler:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 2\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-m54ne8uMmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef9672a-2afe-4e77-8800-e81866eb3e9c"
      },
      "source": [
        "print('Total number of steps: {}'.format(total_steps))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of steps: 14210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiDKq4cLQG6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2a9755-b64c-4e9b-bb7b-80973c693fd2"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    \n",
        "    print('Training {:,} batches...'.format(len(train_dataloader)))\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "    update_interval = good_update_interval(\n",
        "                total_iters = len(train_dataloader), \n",
        "                num_desired_updates = 15\n",
        "            )\n",
        "\n",
        "    num_batches = len(train_dataloader)\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % update_interval == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            step_per_sec = (time.time() - t0) / step\n",
        "            remaining_sec = step_per_sec * (num_batches - step)\n",
        "            remaining = format_time(remaining_sec)\n",
        "            print('  Batch {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(step, num_batches, elapsed, remaining))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_seg_ids = batch[2].to(device)\n",
        "        b_start_pos = batch[3].to(device)\n",
        "        b_end_pos = batch[4].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        token_type_ids = b_seg_ids,\n",
        "                        start_positions=b_start_pos,\n",
        "                        end_positions=b_end_pos)\n",
        "\n",
        "        (loss, start_logits, end_logits) = outputs\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    t0_val = time.time()\n",
        "    pred_start, pred_end, true_start, true_end = [], [], [], []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_seg_ids = batch[2].to(device)\n",
        "        b_start_pos = batch[3].to(device)\n",
        "        b_end_pos = batch[4].to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=b_seg_ids, \n",
        "                            attention_mask=b_input_mask,\n",
        "                            start_positions=b_start_pos,\n",
        "                            end_positions=b_end_pos)\n",
        "\n",
        "        (loss, start_logits, end_logits) = outputs        \n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "        start_logits = start_logits.detach().cpu().numpy()\n",
        "        end_logits = end_logits.detach().cpu().numpy()\n",
        "      \n",
        "        b_start_pos = b_start_pos.to('cpu').numpy()\n",
        "        b_end_pos = b_end_pos.to('cpu').numpy()\n",
        "\n",
        "        answer_start = np.argmax(start_logits, axis=1)\n",
        "        answer_end = np.argmax(end_logits, axis=1)\n",
        "\n",
        "        pred_start.append(answer_start)\n",
        "        pred_end.append(answer_end)\n",
        "        true_start.append(b_start_pos)\n",
        "        true_end.append(b_end_pos)\n",
        "\n",
        "    pred_start = np.concatenate(pred_start, axis=0)\n",
        "    pred_end = np.concatenate(pred_end, axis=0)\n",
        "    true_start = np.concatenate(true_start, axis=0)\n",
        "    true_end = np.concatenate(true_end, axis=0)\n",
        "\n",
        "    num_start_correct = np.sum(pred_start == true_start)\n",
        "    num_end_correct = np.sum(pred_end == true_end)\n",
        "\n",
        "    total_correct = num_start_correct + num_end_correct\n",
        "    total_indices = len(true_start) + len(true_end)\n",
        "\n",
        "    avg_val_accuracy = float(total_correct) / float(total_indices)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0_val)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training 7,105 batches...\n",
            "  Batch     500  of    7,105.    Elapsed: 0:07:30. Remaining: 1:39:01\n",
            "  Batch   1,000  of    7,105.    Elapsed: 0:15:02. Remaining: 1:31:49\n",
            "  Batch   1,500  of    7,105.    Elapsed: 0:22:36. Remaining: 1:24:27\n",
            "  Batch   2,000  of    7,105.    Elapsed: 0:30:09. Remaining: 1:16:58\n",
            "  Batch   2,500  of    7,105.    Elapsed: 0:37:42. Remaining: 1:09:27\n",
            "  Batch   3,000  of    7,105.    Elapsed: 0:45:16. Remaining: 1:01:57\n",
            "  Batch   3,500  of    7,105.    Elapsed: 0:52:50. Remaining: 0:54:25\n",
            "  Batch   4,000  of    7,105.    Elapsed: 1:00:24. Remaining: 0:46:53\n",
            "  Batch   4,500  of    7,105.    Elapsed: 1:07:57. Remaining: 0:39:20\n",
            "  Batch   5,000  of    7,105.    Elapsed: 1:15:30. Remaining: 0:31:47\n",
            "  Batch   5,500  of    7,105.    Elapsed: 1:23:04. Remaining: 0:24:14\n",
            "  Batch   6,000  of    7,105.    Elapsed: 1:30:37. Remaining: 0:16:41\n",
            "  Batch   6,500  of    7,105.    Elapsed: 1:38:10. Remaining: 0:09:08\n",
            "  Batch   7,000  of    7,105.    Elapsed: 1:45:44. Remaining: 0:01:35\n",
            "\n",
            "  Average training loss: 1.23\n",
            "  Training epoch took: 1:47:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "  Validation Loss: 0.92\n",
            "  Validation took: 0:00:45\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training 7,105 batches...\n",
            "  Batch     500  of    7,105.    Elapsed: 0:07:33. Remaining: 1:39:51\n",
            "  Batch   1,000  of    7,105.    Elapsed: 0:15:07. Remaining: 1:32:15\n",
            "  Batch   1,500  of    7,105.    Elapsed: 0:22:39. Remaining: 1:24:39\n",
            "  Batch   2,000  of    7,105.    Elapsed: 0:30:12. Remaining: 1:17:06\n",
            "  Batch   2,500  of    7,105.    Elapsed: 0:37:45. Remaining: 1:09:33\n",
            "  Batch   3,000  of    7,105.    Elapsed: 0:45:18. Remaining: 1:02:00\n",
            "  Batch   3,500  of    7,105.    Elapsed: 0:52:51. Remaining: 0:54:26\n",
            "  Batch   4,000  of    7,105.    Elapsed: 1:00:24. Remaining: 0:46:53\n",
            "  Batch   4,500  of    7,105.    Elapsed: 1:07:57. Remaining: 0:39:20\n",
            "  Batch   5,000  of    7,105.    Elapsed: 1:15:31. Remaining: 0:31:47\n",
            "  Batch   5,500  of    7,105.    Elapsed: 1:23:04. Remaining: 0:24:14\n",
            "  Batch   6,000  of    7,105.    Elapsed: 1:30:37. Remaining: 0:16:41\n",
            "  Batch   6,500  of    7,105.    Elapsed: 1:38:10. Remaining: 0:09:08\n",
            "  Batch   7,000  of    7,105.    Elapsed: 1:45:43. Remaining: 0:01:35\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epoch took: 1:47:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation Loss: 0.93\n",
            "  Validation took: 0:00:45\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xgvwYTHCrs4"
      },
      "source": [
        "**Training Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "**Checking for Over-Fitting**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "42e81afa-763c-45e1-bef6-53b5e27d95dd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "pd.set_option('precision', 2)\n",
        "df_stats"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.23</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1:47:19</td>\n",
              "      <td>0:00:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1:47:18</td>\n",
              "      <td>0:00:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               1.23         0.92           0.72       1:47:19         0:00:45\n",
              "2               0.70         0.93           0.73       1:47:18         0:00:45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33wZGe5eWKEI"
      },
      "source": [
        "The validation loss has remained constant in the two epochs (very minimal increase is observed). Training the model any further will result in overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-M5ABsu6KX6"
      },
      "source": [
        "# 4.Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-AbUAJd6KX7"
      },
      "source": [
        "Loading the holdout dataset and testing the fine-tuned BERT's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiIjg4LEpPfe"
      },
      "source": [
        "**Parsing Test Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrfD3PzMGsTm"
      },
      "source": [
        "There are **3 answers** provided for every question. These are three human-provided answers, and they don't always agree. For example, for the question:\n",
        "\n",
        "```\n",
        "Where did Super Bowl 50 take place?\n",
        "```\n",
        "\n",
        "The annotators produced:\n",
        "```\n",
        "   {'answer_start': 403, 'text': 'Santa Clara, California'}\n",
        "   {'answer_start': 355, 'text': \"Levi's Stadium\"}\n",
        "   {'answer_start': 355, 'text': \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"}\n",
        "```\n",
        "\n",
        "Since all three seem acceptable, BERT's prediction to all three correct answers are compared, and  the highest F1 score that BERT gets among the three is considered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS9qRVcHGsTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d768a055-7ff5-4cb3-cde3-bfbeb31d973d"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(os.path.join('./squad_dataset/dev-v1.1.json'), \"r\", encoding=\"utf-8\") as reader:\n",
        "    input_data = json.load(reader)[\"data\"]\n",
        "\n",
        "print_count = 0\n",
        "print('Unpacking SQuAD Examples...')\n",
        "\n",
        "print('Articles:')\n",
        "\n",
        "examples = []\n",
        "for entry in input_data:\n",
        "    title = entry[\"title\"]\n",
        "    print('  ', title)\n",
        "    for paragraph in entry[\"paragraphs\"]:\n",
        "        context_text = paragraph[\"context\"]\n",
        "        for qa in paragraph[\"qas\"]:\n",
        "            ex = {}\n",
        "            ex['qas_id'] = qa[\"id\"]\n",
        "            ex['question_text'] = qa[\"question\"]\n",
        "            ex['answers'] = qa[\"answers\"]\n",
        "            ex['title'] = title\n",
        "            ex['context_text'] = context_text\n",
        "            examples.append(ex)\n",
        "print('DONE!')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unpacking SQuAD Examples...\n",
            "Articles:\n",
            "   Super_Bowl_50\n",
            "   Warsaw\n",
            "   Normans\n",
            "   Nikola_Tesla\n",
            "   Computational_complexity_theory\n",
            "   Teacher\n",
            "   Martin_Luther\n",
            "   Southern_California\n",
            "   Sky_(United_Kingdom)\n",
            "   Victoria_(Australia)\n",
            "   Huguenot\n",
            "   Steam_engine\n",
            "   Oxygen\n",
            "   1973_oil_crisis\n",
            "   Apollo_program\n",
            "   European_Union_law\n",
            "   Amazon_rainforest\n",
            "   Ctenophora\n",
            "   Fresno,_California\n",
            "   Packet_switching\n",
            "   Black_Death\n",
            "   Geology\n",
            "   Newcastle_upon_Tyne\n",
            "   Victoria_and_Albert_Museum\n",
            "   American_Broadcasting_Company\n",
            "   Genghis_Khan\n",
            "   Pharmacy\n",
            "   Immune_system\n",
            "   Civil_disobedience\n",
            "   Construction\n",
            "   Private_school\n",
            "   Harvard_University\n",
            "   Jacksonville,_Florida\n",
            "   Economic_inequality\n",
            "   Doctor_Who\n",
            "   University_of_Chicago\n",
            "   Yuan_dynasty\n",
            "   Kenya\n",
            "   Intergovernmental_Panel_on_Climate_Change\n",
            "   Chloroplast\n",
            "   Prime_number\n",
            "   Rhine\n",
            "   Scottish_Parliament\n",
            "   Islamism\n",
            "   Imperialism\n",
            "   United_Methodist_Church\n",
            "   French_and_Indian_War\n",
            "   Force\n",
            "DONE!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4VnY9cPGsTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb428dbb-bd22-458e-b50b-75892db97280"
      },
      "source": [
        "print('There are {:,} test examples.'.format(len(examples)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 10,570 test examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBV0qHNaNT7R"
      },
      "source": [
        "**Locating Test Answers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6t4DoepSgtZ"
      },
      "source": [
        "For the test samples, a 2-pass approach has been followed to tokenize the dataset. \n",
        "\n",
        "In the first pass,all the samples are tokenized **without any truncation or padding**, which allows us to correctly locate the answers, even if their token indices are greater than 384.\n",
        "\n",
        "In the second pass, the samples are tokenized and encoded , with padding and truncation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCVlKb7zoRMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d041449-c2f9-4cfc-9c39-ae1e143c3926"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import logging\n",
        "\n",
        "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
        "\n",
        "t0 = time.time()\n",
        "start_positions = []\n",
        "end_positions = []\n",
        "num_clipped_answers = 0\n",
        "num_impossible = 0\n",
        "\n",
        "update_interval = good_update_interval(\n",
        "            total_iters = len(examples), \n",
        "            num_desired_updates = 15\n",
        "        )\n",
        "\n",
        "print('Processing {:,} examples...'.format(len(examples)))\n",
        "\n",
        "for (ex_num, ex) in enumerate(examples):\n",
        "\n",
        "    if (ex_num % update_interval) == 0 and not (ex_num == 0):\n",
        "\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        ex_per_sec = (time.time() - t0) / ex_num\n",
        "        remaining_sec = ex_per_sec * (len(examples) - ex_num)\n",
        "        remaining = format_time(remaining_sec)\n",
        "        print('  Example {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(ex_num, len(examples), elapsed, remaining))\n",
        "    start_options = []\n",
        "    end_options = []\n",
        "\n",
        "    encoded_stored = False\n",
        "    for answer in ex['answers']:\n",
        "        answer_tokens = tokenizer.tokenize(answer['text'])\n",
        "        sentinel_str = ' '.join(['[MASK]']*len(answer_tokens))\n",
        "        start_char_i = answer['answer_start']\n",
        "        end_char_i = start_char_i + len(answer['text'])\n",
        "        context_w_sentinel = ex['context_text'][:start_char_i] + \\\n",
        "                            sentinel_str + \\\n",
        "                            ex['context_text'][end_char_i:]\n",
        "        input_ids = tokenizer.encode(\n",
        "            ex['question_text'], \n",
        "            context_w_sentinel,\n",
        "            add_special_tokens = True, \n",
        "            #max_length = max_len,\n",
        "            pad_to_max_length = False,\n",
        "            truncation = False,\n",
        "        )\n",
        "        mask_token_indices = np.where(np.array(input_ids) == tokenizer.mask_token_id)[0]\n",
        "        assert(len(mask_token_indices) == len(answer_tokens))           \n",
        "        start_index = mask_token_indices[0]\n",
        "        end_index = mask_token_indices[-1]\n",
        "        start_options.append(start_index)\n",
        "        end_options.append(end_index)\n",
        "    \n",
        "    start_positions.append(start_options)\n",
        "    end_positions.append(end_options)\n",
        "\n",
        "print('DONE.  Tokenization took {:}'.format(format_time(time.time() - t0)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 10,570 examples...\n",
            "  Example   1,000  of   10,570.    Elapsed: 0:00:06. Remaining: 0:00:55\n",
            "  Example   2,000  of   10,570.    Elapsed: 0:00:11. Remaining: 0:00:47\n",
            "  Example   3,000  of   10,570.    Elapsed: 0:00:17. Remaining: 0:00:42\n",
            "  Example   4,000  of   10,570.    Elapsed: 0:00:25. Remaining: 0:00:41\n",
            "  Example   5,000  of   10,570.    Elapsed: 0:00:34. Remaining: 0:00:38\n",
            "  Example   6,000  of   10,570.    Elapsed: 0:00:41. Remaining: 0:00:31\n",
            "  Example   7,000  of   10,570.    Elapsed: 0:00:49. Remaining: 0:00:25\n",
            "  Example   8,000  of   10,570.    Elapsed: 0:00:56. Remaining: 0:00:18\n",
            "  Example   9,000  of   10,570.    Elapsed: 0:01:02. Remaining: 0:00:11\n",
            "  Example  10,000  of   10,570.    Elapsed: 0:01:10. Remaining: 0:00:04\n",
            "DONE.  Tokenization took 0:01:15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2cNKUUdStRt"
      },
      "source": [
        "Effect of truncation strategy on the  test set questions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W6fhTTMrM4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d710f36-457b-49b3-acc7-1b94aa68c30b"
      },
      "source": [
        "num_impossible = 0\n",
        "num_clipped = 0\n",
        "\n",
        "for (start_options, end_options) in zip(start_positions, end_positions):\n",
        "\n",
        "    is_possible = False\n",
        "    for i in range(0, len(start_options)):\n",
        "        if (start_options[i] < max_len) and (end_options[i] < max_len):\n",
        "            is_possible = True\n",
        "        if (start_options[i] > max_len) or (end_options[i] > max_len):\n",
        "            num_clipped += 1\n",
        "    if not is_possible:\n",
        "        num_impossible += 1\n",
        "\n",
        "print('')\n",
        "\n",
        "print('Samples w/ all answers clipped: {:,} of {:,} ({:.2%})'.format(num_impossible, len(examples), float(num_impossible) / float(len(examples))))\n",
        "\n",
        "addtl_clipped = num_clipped - (num_impossible * 3)\n",
        "total_answers = len(examples) * 3\n",
        "print('\\n    Additional clipped answers: {:,} of {:,}'.format(addtl_clipped, total_answers))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Samples w/ all answers clipped: 31 of 10,570 (0.29%)\n",
            "\n",
            "    Additional clipped answers: 19 of 31,710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RvMIcRhrCxS"
      },
      "source": [
        "**Tokenizing and Encoding the  Test Samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXmTMK9nqX9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64627ea3-c1b5-4e73-e98d-b64fada24223"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "t0 = time.time()\n",
        "all_input_ids = []\n",
        "attention_masks = []\n",
        "segment_ids = [] \n",
        "\n",
        "update_interval = good_update_interval(\n",
        "            total_iters = len(examples), \n",
        "            num_desired_updates = 15\n",
        "        )\n",
        "\n",
        "print('Tokenizing {:,} examples...'.format(len(examples)))\n",
        "\n",
        "for (ex_num, ex) in enumerate(examples):\n",
        "\n",
        "    if (ex_num % update_interval) == 0 and not (ex_num == 0):\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        ex_per_sec = (time.time() - t0) / ex_num\n",
        "        remaining_sec = ex_per_sec * (len(examples) - ex_num)\n",
        "        remaining = format_time(remaining_sec)\n",
        "        print('  Example {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(ex_num, len(examples), elapsed, remaining))\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        ex['question_text'], \n",
        "        ex['context_text'],\n",
        "        add_special_tokens = True,\n",
        "        max_length = max_len,\n",
        "        pad_to_max_length = True,\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt',\n",
        "    )\n",
        "    input_ids = encoded_dict['input_ids']\n",
        " \n",
        "    all_input_ids.append(input_ids)\n",
        "    attention_masks.append(encoded_dict['attention_mask'])    \n",
        "    segment_ids.append(encoded_dict['token_type_ids'])\n",
        "all_input_ids = torch.cat(all_input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "segment_ids = torch.cat(segment_ids, dim=0)\n",
        "\n",
        "print('DONE.  Tokenization took {:}'.format(format_time(time.time() - t0)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing 10,570 examples...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Example   1,000  of   10,570.    Elapsed: 0:00:02. Remaining: 0:00:20\n",
            "  Example   2,000  of   10,570.    Elapsed: 0:00:04. Remaining: 0:00:16\n",
            "  Example   3,000  of   10,570.    Elapsed: 0:00:06. Remaining: 0:00:15\n",
            "  Example   4,000  of   10,570.    Elapsed: 0:00:08. Remaining: 0:00:13\n",
            "  Example   5,000  of   10,570.    Elapsed: 0:00:11. Remaining: 0:00:12\n",
            "  Example   6,000  of   10,570.    Elapsed: 0:00:13. Remaining: 0:00:10\n",
            "  Example   7,000  of   10,570.    Elapsed: 0:00:16. Remaining: 0:00:08\n",
            "  Example   8,000  of   10,570.    Elapsed: 0:00:18. Remaining: 0:00:06\n",
            "  Example   9,000  of   10,570.    Elapsed: 0:00:20. Remaining: 0:00:04\n",
            "  Example  10,000  of   10,570.    Elapsed: 0:00:23. Remaining: 0:00:01\n",
            "DONE.  Tokenization took 0:00:24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJJVmwstqzEn"
      },
      "source": [
        "\n",
        "\n",
        "**Evaluate On Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqNzZkUx6KYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852590ea-7b28-4a64-ae10-d327e7211819"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "\n",
        "t0 = time.time()\n",
        "pred_start = []\n",
        "pred_end = []\n",
        "num_test_samples = all_input_ids.shape[0]\n",
        "batch_size = 16\n",
        "\n",
        "num_batches = int(np.ceil(num_test_samples / batch_size))\n",
        "\n",
        "print('Evaluating on {:,} test batches...'.format(num_batches))\n",
        "\n",
        "batch_num = 0\n",
        "for start_i in range(0, num_test_samples, batch_size):\n",
        "    if ((batch_num % 50) == 0) and not (batch_num == 0):\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "      batches_per_sec = (time.time() - t0) / batch_num\n",
        "      remaining_sec = batches_per_sec * (num_batches - batch_num)\n",
        "      remaining = format_time(remaining_sec)\n",
        "      print('  Batch {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(batch_num, num_batches, elapsed, remaining))\n",
        "\n",
        "    end_i = min(start_i + batch_size, num_test_samples)\n",
        "    b_input_ids = all_input_ids[start_i:end_i, :]\n",
        "    b_attn_masks = attention_masks[start_i:end_i, :]\n",
        "    b_seg_ids = segment_ids[start_i:end_i, :]   \n",
        "\n",
        "    b_input_ids = b_input_ids.to(device)\n",
        "    b_attn_masks = b_attn_masks.to(device)\n",
        "    b_seg_ids = b_seg_ids.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        (start_logits, end_logits) = model(b_input_ids, \n",
        "                                           attention_mask=b_attn_masks,\n",
        "                                           token_type_ids=b_seg_ids)\n",
        "    start_logits = start_logits.detach().cpu().numpy()\n",
        "    end_logits = end_logits.detach().cpu().numpy()\n",
        "\n",
        "    answer_start = np.argmax(start_logits, axis=1)\n",
        "    answer_end = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    pred_start.append(answer_start)\n",
        "    pred_end.append(answer_end)\n",
        "\n",
        "    batch_num += 1\n",
        "\n",
        "pred_start = np.concatenate(pred_start, axis=0)\n",
        "pred_end = np.concatenate(pred_end, axis=0)\n",
        "\n",
        "print('    DONE.')\n",
        "\n",
        "print('\\nEvaluation took {:.0f} seconds.'.format(time.time() - t0))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating on 661 test batches...\n",
            "  Batch      50  of      661.    Elapsed: 0:00:21. Remaining: 0:04:20\n",
            "  Batch     100  of      661.    Elapsed: 0:00:43. Remaining: 0:04:00\n",
            "  Batch     150  of      661.    Elapsed: 0:01:03. Remaining: 0:03:35\n",
            "  Batch     200  of      661.    Elapsed: 0:01:23. Remaining: 0:03:12\n",
            "  Batch     250  of      661.    Elapsed: 0:01:44. Remaining: 0:02:51\n",
            "  Batch     300  of      661.    Elapsed: 0:02:05. Remaining: 0:02:30\n",
            "  Batch     350  of      661.    Elapsed: 0:02:25. Remaining: 0:02:09\n",
            "  Batch     400  of      661.    Elapsed: 0:02:46. Remaining: 0:01:48\n",
            "  Batch     450  of      661.    Elapsed: 0:03:06. Remaining: 0:01:27\n",
            "  Batch     500  of      661.    Elapsed: 0:03:27. Remaining: 0:01:07\n",
            "  Batch     550  of      661.    Elapsed: 0:03:48. Remaining: 0:00:46\n",
            "  Batch     600  of      661.    Elapsed: 0:04:08. Remaining: 0:00:25\n",
            "  Batch     650  of      661.    Elapsed: 0:04:29. Remaining: 0:00:05\n",
            "    DONE.\n",
            "\n",
            "Evaluation took 273 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKoBf7Tm4Ync"
      },
      "source": [
        "#5.Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abzMLjfzEjng"
      },
      "source": [
        "There are two standard approaches to scoring results on the SQuAD benchmark:\n",
        "\n",
        "1. Exact Match\n",
        "2. F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYV1A4nIE5Q8"
      },
      "source": [
        "**Exact Match**\n",
        "\n",
        "For this metric, the number of predicted start indices that are equal to the correct ones are added up. It is done for  the end indices as well, such that there are actually two \"points\" for every sample.\n",
        "\n",
        "To handle the 3 possible answers, we score our predictions against each of the answers separately, and select the  answer which best matches our prediction. So for each test sample, the highest possible score is 2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sLFKdVV9Ifw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b4b0b6-559b-4390-8886-2467817f01d9"
      },
      "source": [
        "\n",
        "total_correct = 0\n",
        "\n",
        "for i in range(0, len(pred_start)):\n",
        "\n",
        "    match_options = []\n",
        "    for j in range (0, len(start_positions[i])):\n",
        "        matches = 0\n",
        "        if pred_start[i] == start_positions[i][j]:\n",
        "            matches += 1\n",
        "        if pred_end[i] == end_positions[i][j]:\n",
        "            matches += 1\n",
        "\n",
        "        match_options.append(matches)\n",
        "\n",
        "    total_correct += (max(match_options))\n",
        "total_indices = len(pred_start) + len(pred_end)\n",
        "\n",
        "print('Correctly predicted indeces: {:,} of {:,} ({:.2%})'.format(\n",
        "    total_correct,\n",
        "    total_indices,\n",
        "    float(total_correct) / float(total_indices)\n",
        "))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correctly predicted indeces: 17,751 of 21,140 (83.97%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCO7vPcP8GgE"
      },
      "source": [
        "**F1 Score**\n",
        "\n",
        "The F1 score gives our model credit for predicting a span which partially intersects the correct one.\n",
        "\n",
        "*Formula :* \n",
        "```python\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "```\n",
        "To handle the 3 possible answers, F1 score for each sample is calculated separately and the one with the highest score is considered. \n",
        "\n",
        "The final F1 score is determined by taking the average over all the test samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9EzmbnI8LRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a89d8d9-9151-484b-d3d1-cce968c040cd"
      },
      "source": [
        "f1s = []\n",
        "for i in range(0, len(pred_start)):\n",
        "    pred_span = set(range(pred_start[i], pred_end[i] + 1))\n",
        "    f1_options = []\n",
        "    for j in range (0, len(start_positions[i])):\n",
        "        true_span = set(range(start_positions[i][j], end_positions[i][j] + 1))    \n",
        "        num_same = len(pred_span.intersection(true_span))\n",
        "        if num_same == 0:\n",
        "            f1_options.append(0)\n",
        "            continue\n",
        "        precision = float(num_same) / float(len(pred_span))\n",
        "        recall = float(num_same) / float(len(true_span))\n",
        "        f1 = (2 * precision * recall) / (precision + recall)\n",
        "        f1_options.append(f1)\n",
        "    f1s.append(max(f1_options))\n",
        "\n",
        "print('Average F1 Score: {:.3f}'.format(np.mean(f1s)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average F1 Score: 0.863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNryoCi9JWng"
      },
      "source": [
        "**Final Score of our fine tuned BERT base model:**\n",
        "\n",
        "```\n",
        "Correctly predicted indices: 17,751 of 21,140 (83.97%)\n",
        "\n",
        "Average F1 Score: 0.863\n",
        "```\n",
        "\n"
      ]
    }
  ]
}